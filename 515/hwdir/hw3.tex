\documentclass[12pt]{article}
\usepackage[sort,longnamesfirst]{natbib}
\usepackage{amsmath,amsfonts}%
\newcommand{\bthet}{ \mbox{\boldmath $\theta$}}
\newcommand{\bOne}{ {\bf 1} }
\newcommand{\lambdaT}{\lambda_{\theta}}
\newcommand{\bTheta}{ \mbox{\boldmath $\Theta$}}
\begin{document}
%\pagestyle{empty}
\begin{center}
\Large
{\bf Homework 3, Stat 515, Spring 2011}\\
\normalsize
Due Friday, February 11th, 2011 \underline{{\bf beginning of class}}\\
\end{center}
\begin{enumerate}
% 4.14 identifying recurrent/transient states
\item Consider two Markov chains on $\Omega=\{1, 2, 3, 4, 5\}$ specified by the following transition probability matrices.
\begin{equation*}
  P_1=
  \begin{bmatrix}
    \frac{1}{2} & 0   & \frac{1}{2}  & 0 & 0 \\
    \frac{1}{4} & \frac{1}{2}   & \frac{1}{4}  & 0 & 0\\
    \frac{1}{2} & 0  & \frac{1}{2}  & 0 & 0\\
    0 & 0   & 0  & \frac{1}{2} & \frac{1}{2}\\
    0 & 0   & 0  & \frac{1}{2} & \frac{1}{2}\\
  \end{bmatrix},
  P_2=
  \begin{bmatrix}
    \frac{1}{4} & \frac{3}{4}   & 0  & 0 & 0 \\
    \frac{1}{2} & \frac{1}{2}   & 0  & 0 & 0\\
    0 & 0  & 1  & 0 & 0\\
    0 & 0   & \frac{1}{3}  & \frac{2}{3} & 0\\
    1 & 0   & 0  & 0 & 0\\
  \end{bmatrix},
\end{equation*}
\begin{enumerate}
\item Specify the classes of the two Markov chains with these transition probability matrices and determine whether the states are transient or recurrent, and if they are recurrent whether they are positive or null recurrent.
\item List the periods of each state of the Markov chain. Are these Markov chains aperiodic? 
\end{enumerate}
% 4. 38 and 39  (mainly interested in showing null  recurrence/pos. recurrence is a class property
\item Define $\mu_{ii}$ as in class, so $\mu_{ii}$ is the expected
  number of transitions until the Markov chain, starting in state $i$,
  makes a transition back to state $i$. Define $\pi_i$ as the long run
  proportion of time the Markov chain, starting in state $i$, spends
  in state $i$. Assume $\pi_i = 1/\mu_{ii}$. Therefore, state $i$ is
  positive recurrent iff $\pi_i>0$. 
\begin{enumerate}
\item Prove that positive recurrence is a class property: Suppose
  state $i$ is positive recurrent and states $i$ and $j$ are in the
  same class.  Prove that state $j$ is also positive recurrent.  Hint:
  show that, for state $j$, there exists $n\in \mathbb{Z}^+$ such that
  $\pi_j \geq \pi_i P_{ij}^n > 0$.
\item Prove that null recurrence is also a class property.
\end{enumerate}
%% 4. 44 understanding how transience affects M.C. behavior
%\item
% 4. 24 understanding stationarity, limiting, marginal distri. of M.C. states.
\item Consider three urns, one colored red, one white, and one blue.
  The red urn contains 1 red and 4 blue balls; the white urn contains
  3 white balls, 2 red balls, and 2 blue balls; the blue urn contains
  4 white balls, 3 red balls, and 2 blue balls.  At the initial stage,
  a ball is randomly selected from the red urn and then returned to
  that urn. At every subsequent stage, a ball is randomly selected
  from the urn whose color is the same as that of the ball previously
  selected and is then returned to that urn. 
\begin{enumerate}
\item Write the state space of this process and the associate initial
  distribution and transition probability matrix. Explain why this
  process is a Markov chain.
\item Does this process have a stationary distribution? Justify your
  answer. You will need to show how each of the requisite conditions
 is satisfied by the Markov chain.
\item Does this process have a limiting distribution? Justify your answer.
\item What is the stationary distribution of this process? 
\item In the long run, what proportion of the selected balls are red?
  What proportion are white?  What proportion are blue?
\item Simulate a Markov chain of length 100,000 using the information
  provided above and count the proportion of times the chain was in
  each of the states. Compare this to your answer. 
\item Suppose you have taken 3 steps, i.e., you start with the initial
  distribution to obtain $X_0$ and use the t.p.m. above to obtain
  state $X_3$ of the Markov chain. What proportion of times would you
  expect $X_3$ to be red, white and blue respectively? Similarly, what
  proportion of times would you expect $X_5$ to be red, white and blue
  respectively? Note that you should use {\tt R} to solve this problem
  (follow the example from the previous homework.)
\item Now simulate 10,000 realizations of the random variables $X_3$
  and $X_5$ using the initial distribution and transition probability
  matrix for this process. Calculate the proportion of times in your
  simulations that $X_3$ and $X_5$ are red, white, and blue
  respectively. Compare these two sets of proportions to their
  respective probabilities from part (g) above.
\end{enumerate} 
%% time reversibility + MCMC basics
\item Consider a Markov chain on the integers (i.e. a Markov chain that has state space 
$\mathbb{Z}$) with transition probabilities given by: %$\{ \dots,-3,-2,-1,0,1,2,3,\dots \}$
\begin{equation*}
  \begin{split}
    P_{i,j}= & \alpha(i,j) q(i,j), \:\:\: \mbox{ if } j \neq i \\
    P_{i,i}= & q(i,i) + \sum_{k\neq i} q(i,k)(1-\alpha(i,k)), \mbox{  with,}\\
    \alpha(i,j) = & \min\left(\frac{\pi_jq(j,i)}{\pi_iq(i,j)}, 1\right).
  \end{split}
\end{equation*}
%$\sum_{i=1}^{\infty} \pi_i=1,\:\:\: \pi_i \geq 0$ and
$q(i,j)$ is the row i column j element of a transition probability
matrix $Q$ where $Q$ defines an irreducible Markov chain on the
integers and $q(i,j)>0$ whenever $q(j,i)>0$ for all $i,j$. \\Also,
$\sum_i \pi_i=1,\:\:\:
\pi_i > 0 \:\: \forall i$. Assume $q(i,i)>0 \:\: \forall i$.\\
Using time reversibility arguments, show that the Markov chain has
stationary probabilities $\{\pi_i\}$, and that these stationary
probabilities are also the limiting probabilities of the Markov chain.
\end{enumerate}
\end{document}
