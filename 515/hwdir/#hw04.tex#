
\documentclass{article}
\usepackage{amsmath, amsfonts,hyperref}
\usepackage{url}
\pagestyle{empty}
\setlength{\textwidth}{6in}
\setlength{\oddsidemargin}{0in}
\setlength{\topmargin}{-.5in}
\setlength{\textheight}{9in}

\begin{document}
%\pagestyle{empty}
\begin{center}
\Large
{\bf Homework 4, Stat 515, Spring 2015}\\
\normalsize
Due Wednesday, February 18, 2015 \underline{{\bf beginning of class}}\\
\end{center}
\begin{enumerate}%{\bf Textbook problems:} {\it Ch.4:} 2,3,5,8, 11,13.\\
\item Define $\mu_{ii}$ as in class, so $\mu_{ii}$ is the expected
  number of transitions until the Markov chain, starting in state $i$,
  makes a transition back to state $i$. Define $\pi_i$ as the long run
  proportion of time the Markov chain, starting in state $i$, spends
  in state $i$. Assume $\pi_i = 1/\mu_{ii}$. Therefore, state $i$ is
  positive recurrent iff $\pi_i>0$. 
\begin{enumerate}
\item Prove that positive recurrence is a class property: Suppose
  state $i$ is positive recurrent and states $i$ and $j$ are in the
  same class.  Prove that state $j$ is also positive recurrent.  Hint:
  show that, for state $j$, there exists $n\in \mathbb{Z}^+$ such that
  $\pi_j \geq \pi_i P_{ij}^n > 0$.
\item Prove that null recurrence is also a class property.
\end{enumerate}
\item Consider the same problem from the previous homework: three
  urns, one colored red, one white, and one blue.  The red urn
  contains 1 red and 4 blue balls; the white urn contains 3 white
  balls, 2 red balls, and 2 blue balls; the blue urn contains 4 white
  balls, 3 red balls, and 2 blue balls.  At the initial stage, a ball
  is randomly selected from the red urn and then returned to that
  urn. At every subsequent stage, a ball is randomly selected from the
  urn whose color is the same as that of the ball previously selected
  and is then returned to that urn.
\begin{enumerate}
\item You have already derived the transition probability matrix and
  the initial distribution of the chain. Let $X_0$ be the initial
  state of the Markov chain. What is $E(X_2)$ if red, white and blue
  are coded as 1,2,3 respectively?
\item Does this process have a stationary distribution? Justify your
  answer. You will need to show how each of the requisite conditions
  is satisfied by the Markov chain.
\item Does this process have a limiting distribution? Justify your answer.
\item In the long run, what proportion of the selected balls are red?
  What proportion are white?  What proportion are blue? Again, justify
  your answer (theoretical results, conditions satisfied).
\item Simulate a Markov chain of length 100,000 using the information
  provided above and count the proportion of times the chain was in
  each of the states. Compare this to your answer. 
\item Suppose you have taken 3 steps, i.e., you start with the initial
  distribution to obtain $X_0$ and use the t.p.m. above to obtain
  state $X_3$ of the Markov chain. What proportion of times would you
  expect $X_3$ to be red, white and blue respectively? Similarly, what
  proportion of times would you expect $X_5$ to be red, white and blue
  respectively? Note that you should use {\tt R} to solve this
  problem.  (Follow the example from the previous homework, as well as
  the sample code discussed in lecture and available on Angel.)
\item Now simulate 10,000 realizations of the random variables $X_2$
  and $X_{20}$ using the initial distribution and transition probability
  matrix for this process. Calculate the proportion of times in your
  simulations that $X_2$ and $X_{20}$ are red, white, and blue
  respectively. Compare these two sets of 3 proportions to their
  respective probabilities from above. {\it Note that here you are
    simulating multiple realizations of $X_2,X_{20}$  in order to
    approximate their expected values. This is different from the
    simulation above where you were simulating a single Markov chain in
    order to approximate its stationary/limiting distribution,
    assuming one exists.}
\end{enumerate}
%\end{enumerate}
\item Consider a Markov chain on states $0,1,\dots$ with transition probabilities given by: 
$$P_{ij} = \frac{1}{i+2} $$  for $j=0,1,\dots, i, i+1$. 
\begin{enumerate}
\item Is this Markov chain irreducible and ergodic? Provide a detailed answer.
\item What is its stationary distribution?
\end{enumerate}
\end{enumerate}
\end{document}
