\input{summary}

\begin{document}


\def \thedate{Mar.~23}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\startframe{Announcements}
\begin{itemize}
\item 
HW \#8 is due next Friday (March 30) at 2:30pm.
\item 
All homework must be turned in electronically from now on.
\item
There is a lot of computing on this assignment; please let me know
early if there will be coding challenges!
\end{itemize}
\end{frame}


\startframe{LOLN-like results}
Theorem:
If a continuous-time M.C. $\{ X_t:t\ge0\}$ is irreducible and 
has a stationary distribution $\pi$, and if 
$g:\Omega\to\bR$ satisfies $E_\pi |g(X)|<\infty$,
then as $t\to\infty$,
\[
\frac1t \int_0^t g(X_s) \, ds \to E_\pi g(X) \quad
\mbox{with probability 1.}
\]
Compare with Proposition 4.3 (the last proposition in Section 4.4).
\notes{I had omitted the words ``with probability 1'' in Wednesday's notes.
This is technically a big mistake, since there are numerous ways that
a sequence of random variables (the LHS is a random variable) can converge
to a real number, so it's important to specify which mode of convergence is
meant.}
\end{frame}

\startframe{Monte Carlo methods}
\begin{itemize}
\item Why ``Monte Carlo''?
\item Ross Chapter 11 is a useful reference for some of the topics here.
\item Example:  Approximating $\pi$
\end{itemize}
\notes{Monte Carlo is a city where gambling occurs, which is based on randomness---hence
the name!  We considered a simple Monte Carlo estimator of the constant $\pi$ in R:
\\
{\tt x <- matrix(runif(2e4), ncol=2) }\\
{\tt  plot(x)} \\
{\tt f <- function(a) a[1]\textasciicircum 2+a[2]\textasciicircum 2 < 1} \\
{\tt 4 * sum(apply(x, 1, f)) / 10000}
}
\end{frame}

\startframe{Monte Carlo methods}
\begin{itemize}
\item Goal:   Find $\mu=E_f g(X)$.
\item Idea:   Use computer to generate i.i.d.~$X_1, \ldots, X_n \sim f$
\item Take $\hat\mu = \frac1n \sum_{i=1}^n g(X_i)$.
\end{itemize}
\notes{Here, $E_f g(X)$ is generally either
\[
\int_{-\infty}^\infty g(x)f(x)\,dx 
\]
or
\[
\sum_{x} g(x) f(x).
\]
}
\end{frame}

\startframe{Monte Carlo methods}
$\hat\mu = \frac1n \sum_{i=1}^n g(X_i)$, where $X_i$ are i.i.d.~from $f$.
\begin{itemize}
\item Why this works:  (Strong or weak) law of large numbers
\item More precise information is provided by the Central Limit Theorem.
\item The above results are true for vectors $X_i$ of arbitrary 
dimension.
\item {\em Thinking about i.i.d.~Monte Carlo $\equiv$ thinking about basic statistics.}
\end{itemize}
\notes{Alternative numerical methods for approximating integrals, like 
numerical quadrature, don't work well in high dimensions.  Yet Monte Carlo methods
can perform well in any dimension.}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}


