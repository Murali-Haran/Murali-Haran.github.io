\input{summary}

\begin{document}


\def \thedate{Feb.~8}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\startframe{Announcements}
\begin{itemize}
\item
Finish Reading Section 5.2 for Monday.
\item 
No class on Friday.
\item 
No office hours tomorrow (but next Thursday is back to normal)
\end{itemize}
\end{frame}

\startframe{4.4 Limiting probabilities}
\begin{itemize}
\item
A word about limiting distribution vs. stationary distribution\ldots
\item
Although ergodicity lists positive recurrence as a condition, it's often more
practical to
  \begin{itemize}
  \item check irreducibility
  \item check aperiodicity
  \item solve $\pi^\top = \pi^\top P$ to get $\pi$ (if possible).
  \end{itemize}
\end{itemize}
\notes{This slide is a comment on some recent questions I've gotten regarding the 
reading (Section 4.4) and the most recent homework.   I mentioned that
the limiting distribution $\pi$ satisfies
\[
\lim_{n\to\infty} P^n = 
\begin{bmatrix}
\quad & \pi^\top & \quad \\
\quad & \pi^\top & \quad \\
& \vdots & \\
\quad & \pi^\top & \quad 
\end{bmatrix}
\]
and the stationary distribution $\pi$ satisfies $\pi^\top = \pi^\top P$.
}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
``Consider a stationary ergodic Markov chain (that is, an ergodic Markov chain
that has been in operation for a long time)\ldots''
\begin{itemize}
\item We now know what ``ergodic'' means:
\item There is a limiting distribution $\pi$ that uniquely solves the
equations $\pi^\top = \pi^\top P$.
\end{itemize}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item
Define $Q_{ij} = P(X_t = j \mid X_{t+1} = i)$.
\item
Use Bayes' theorem to prove 
\[
Q_{ij} = \frac{\pi_j P_{ji}}{\pi_i}.
\]
\item
What if $P_{ij}=Q_{ij}$ for all $i,j$?
\end{itemize}
\notes{The proof of
$Q_{ij} = \frac{\pi_j P_{ji}}{\pi_i}$ is straightforward using the 
definition of conditional probability.
}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item
When $P_{ij}=Q_{ij}$ for all $i,j$, the process is said
to be {\em time reversible}.
\item 
To gain intuition, write
\[
Q_{ij} = P_{ij} = \frac{\pi_j P_{ji}}{\pi_i}
\quad\mbox{as}\quad
\pi_iP_{ij} = \pi_j P_{ji}.
\]
\item
Interpretation:  Proportionally, there are just as many $i\rightarrow j$
transitions as $j\rightarrow i$ transitions.
\end{itemize}
\notes{
We had a lengthy discussion about the intuition; it is based on the idea that
\begin{eqnarray*}
P(\mbox{a randomly chosen transition is from $i\to j$}) &=& \pi_i P_{ij}, \\
P(\mbox{a randomly chosen transition is from $i\to j$}) &=& \pi_j P_{ji}.
\end{eqnarray*}
}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item Example of a time reversible Markov chain:
random walk on $0, 1, \ldots, M$ where you can stay at the edges (0 and $M$) but you
can't go beyond them.
\item The fact that this MC is time reversible can help find its stationary probabilities.
\end{itemize}
\notes{By inspection, we conclude that this MC is irreducible, aperiodic, and
time reversible.  This last condition gives us an additional tool to use in 
finding the limiting $\pi$ vector.  For instance, we argued that
\[
\alpha_0 = P_{01} = \frac{\pi_1}{\pi_0} P_{10} = \frac{\pi_1}{\pi_0} (1-\alpha_1),
\]
where $\alpha_0$ and $\alpha_1$ are given.  A whole series of these equations
is derived in the ``Consider a random walk with states $0, 1, \ldots, M$ \ldots''
example in Section~4.8.  As a special case, we ended class by defining
the Ehrenfest model.}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}


