\input{lecture}

\begin{document}


\def \thedate{Apr.~6}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\startframe{Announcements}
\begin{itemize}
\item 
HW \#10 is due on Friday, April 13 at 2:30pm.
\item 
All homework must be turned in electronically from now on.
\item 
Only 2 more homeworks!  (Only best 10 out of 11 grades will count.)
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
Importance sampling can be unstable:
\begin{itemize}
\item Suppose $q(x)$ is small for some $x$ where $g(x)f(x)$ is big.  
\item Then $g(x)f(x)/q(x)$ will have extreme outliers that are rare.
\item If these values are rare enough, we may never see them and thus
we may underestimate the M.C. standard error.
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
Importance sampling standard errors
\begin{itemize}
\item Plain importance sampling:  Easy
\item Ratio importance sampling:  Use delta method to derive
\[
{\Var} \left( \frac{ \frac1n\sum_i A_i}{\frac1n\sum_i B_i} \right) \approx
\frac{1}{\mu_B^2}
\begin{bmatrix}
1 & \frac{-\mu_A}{\mu_B}
\end{bmatrix}
\begin{bmatrix}
\sigma^2_A & \sigma_{AB} \\ \sigma_{AB} & \sigma^2_B
\end{bmatrix}
\begin{bmatrix}
1 \\ \frac{-\mu_A}{\mu_B}
\end{bmatrix}
\]
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
(Ratio) importance sampling application:
\begin{itemize}
\item Goal:  Estimate $\mu(\theta) = \E_{f_\theta} g(X)$ for $\theta\in\Theta$.
\item Plain Monte Carlo sampling:  Draw new sample for each $\theta\in\Theta$.
\item Importance sampling:  Draw a {\em single} sample from $q(x)$, etc.
\item Ratio importance sampling:  When normalizing ``constant'' unknown.
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
Ratio importance sampling for $\mu(\theta)= \E_{f_\theta} g(X)$:
\begin{itemize}
\item Estimate:  $\tilde\mu = \sum_{i=1}^n g(X_i)w\theta(X_i)$, where
\[
w_\theta(X_i) = \frac{r_\theta(X_i)/q(X_i)}{\sum_{j=1}^n r_\theta(X_j)/q(X_j)}
\]
and $f_\theta(x) = \alpha(\theta) r_\theta(x)$.
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
Ratio importance sampling for $\mu(\theta)= \E_{f_\theta} g(X)$:
\begin{itemize}
\item Estimate:  $\tilde\mu = \sum_{i=1}^n g(X_i)w\theta(X_i)$.
\item Need $q(x)>0$ whenever $f_\theta(x)>0$ for any $\theta$.  
\item Ideally, $q(x)$ not near zero whenever $f_\theta(x)$ large for any $x$,
though this may be hard to do.
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
Related:  Monte Carlo MLE
\begin{itemize}
\item
Given $X\sim f_\theta(x) = \exp\{\theta^\top s(x)\} / c(\theta)$,
write  log-likelihood as
\[
\ell(\theta) = \ell(\theta_0) + (\theta-\theta_0)^\top s(X) - 
\log E_{\theta_0} \exp\{( \theta-\theta_0)^\top s(Y)\}.
\]
\item Use $Y_1, \ldots, Y_m\sim f_{\theta_0}$ to approximate
$\ell(\theta)-\ell(\theta_0)$.
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
How to find $q(x)$ for importance sampling:
\begin{itemize}
\item Exponential tilting (see Ross, Section 11.6.4)
\item Defensive importance functions 
\item Laplace approximation
\item Others:  See J. Liu, {\it Monte Carlo Strategies in Scientific Computing}
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}




