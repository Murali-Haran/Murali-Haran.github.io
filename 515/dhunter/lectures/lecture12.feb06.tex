\input{lecture}

\begin{document}


\def \thedate{Feb.~6}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\startframe{Announcements}
\begin{itemize}
\item
Please read Sections 5.1, 5.2.1, 5.2.2, and 5.2.3 (both editions) for Wednesday.
\item 
No class this Friday.
\item 
Office hours will be this {\bf Tuesday} (not Thursday) from 2:00-4:00.
\end{itemize}
\end{frame}

\startframe{4.4 Limiting Probabilities}
Theorem:  For an irreducible ergodic (time-homogeneous) 
Markov chain with transition matrix $P$,
\[
\lim_{n\to\infty} P^n_{ij} 
\]
exists and it does not depend on $i$ (it does generally depend on $j$).
\end{frame}

\startframe{4.4 Limiting Probabilities}
Corollary:  For an irreducible ergodic (time-homogeneous) 
Markov chain with transition matrix $P$,
the equations 
\[
\pi_j = \sum_{i=0}^{\mbox{\# states}} \pi_i P_{ij}, \qquad j = 0, 1, 2, \ldots
\]
have solution 
\[
\pi_j=\lim_{n\to\infty} P^n_{ij}.
\]
\end{frame}

\startframe{4.4 Limiting Probabilities}
Example:
\begin{itemize}
\item
Let $\alpha$ be the probability of rain after a rainy day.
\item
Let $\beta$ be the probability of rain after a non-rainy day.
\end{itemize}
What are the limiting probabilities?
\end{frame}

\startframe{4.4 Limiting Probabilities}
One last bit of terminology:
\begin{itemize}
\item stationary probability
\end{itemize}
\end{frame}

\startframe{4.4 Limiting Probabilities}
More facts we will not prove:
\begin{itemize}
\item If we assume $\sum_j \pi_j=1$, then the solution in the corollary is unique.
\item The $\pi_j$ from the corollary are the stationary probabilities.
\end{itemize}
\end{frame}

\startframe{4.4 Limiting Probabilities}
More facts we will not prove:
\begin{itemize}
\item Aperiodicity is not necessary in order for the equations in the corollary to have a 
unique solution.  However, for irreducible chains, positive recurrence is necessary.
\item Stationary probabilities exist even for periodic irreducible chains.
\end{itemize}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
``Consider a stationary ergodic Markov chain (that is, an ergodic Markov chain
that has been in operation for a long time)\ldots''
\begin{itemize}
\item We now know what ``ergodic'' means:
\item There is a limiting distribution $\pi$ that uniquely solves the
equations $\pi^\top = \pi^\top P$.
\end{itemize}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item
Define $Q_{ij} = P(X_t = j \mid X_{t+1} = i)$.
\item
Use Bayes' theorem to prove 
\[
Q_{ij} = \frac{\pi_j P_{ji}}{\pi_i}.
\]
\item
What if $P_{ij}=Q_{ij}$ for all $i,j$?
\end{itemize}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item
When $P_{ij}=Q_{ij}$ for all $i,j$, the process is said
to be {\em time reversible}.
\item 
To gain intuition, write
\[
Q_{ij} = \frac{\pi_j P_{ji}}{\pi_i}
\quad\mbox{as}\quad
\pi_iP_{ij} = \pi_j P_{ji}.
\]
\item
Interpretation:  Proportionally, there are just as many $i\rightarrow j$
transitions as $j\rightarrow i$ transitions.
\end{itemize}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item
$\pi_iP_{ij} = \pi_j P_{ji}$ is called {\em detailed balance}.
\item
Interpretation:  There are just as many $i\rightarrow j$
transitions as $j\rightarrow i$ transitions.
\item Example of a time reversible Markov chain:
random walk on $0, 1, \ldots, M$ where you can stay at the edges (0 and $M$) but you
can't go beyond them.
\end{itemize}
\end{frame}

\startframe{4.8 Time Reversible Markov Chains}
\begin{itemize}
\item
$\pi_iP_{ij} = \pi_j P_{ji}$ is called {\em detailed balance}.
\item
Equivalently, we can derive the so-called 
Kolmogorov circulation condition:
\[
P_{ij}P_{jk}P_{ki} = P_{ik}P_{kj}P_{ji}
\]
is a special case.
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}


