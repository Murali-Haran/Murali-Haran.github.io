\input{summary}

\begin{document}


\def \thedate{Mar.~28}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\startframe{Announcements}
\begin{itemize}
\item 
HW \#8 is due on Friday, March 30 at 2:30pm.
\item 
All homework must be turned in electronically from now on.
\item 
See sample code for problems 1(a) and 1(b).
\end{itemize}
\end{frame}


\startframe{Monte Carlo methods}
How do you generate $X\sim F$ given $U\sim\mbox{Unif}(0,1)$?
\begin{itemize}
\item
Some special cases are covered in Ross, section 11.3
\item
General ``inversion'' method based on  quantile function
\[
F^-(u)  \stackrel{\rm def}{=} \inf \{ x : u\le F(x)\}.
\]
Can prove:  $F^-(U)\sim F$, i.e., $P[F^-(U) \le x] = F(x)$ for all $x$.
\end{itemize}
\notes{
In the special case when $F^{-1}(u)$, the inverse function, exists, there is
a simple one-line proof of the fact above:
\[
P[ F^{-1}(U) \le x ] = P [F(F^{-1}(U)) \le F(x)] = P[U\le F(x)] = F(x).
\]
}
\end{frame}

\startframe{Monte Carlo methods}
Examples:
\begin{itemize}
\item Generate $X\sim\mbox{Exponential}(1)$.
\item Generate $X\sim\mbox{Standard Cauchy}$.
\end{itemize}
\notes{
If $U$ is standard uniform, then the inversion method shows that
$-\log(1-U)$ is standard exponential and 
$\tan[\pi(U-\frac12)]$ is standard Cauchy.
}
\end{frame}

\startframe{Monte Carlo methods}
Problems with the inversion method:
\begin{itemize}
\item Only works in one dimension
\item Explicit quantile functions are not always available
\item Explicit $F(x)$ may not even be possible; for instance, 
$f(x)$ may be known only up to a constant.
\end{itemize}
\end{frame}

\startframe{Monte Carlo methods}
Rejection sampling works much more generally than inversion method.
\begin{itemize}
\item Given:  An ``easier'' density $g$ and known $K$ such that $Kg(x)\ge f(x)$.
\item Idea:  Sample repeatedly from $g$, but only keep each sampled value
with probability $f(x)/Kg(x)$.
\end{itemize}
\notes{
There is a nice graphical intuition here, which we discussed in class.
The algorithm works like this:
\begin{enumerate}
\item Generate $X\sim g$.
\item Generate $U\sim \mbox{uniform}(0,1)$.
\item If $U < f(X)/[Kg(X)]$, accept $X$; otherwise, reject it and start over.
\item Conditional on an acceptance, $X\sim f$.  
\end{enumerate}
}
\end{frame}


\startframe{Monte Carlo methods}
Rejection sampling notes
\begin{itemize}
\item Only necessary to know $f$ and $g$ up to constants.
\item Often better to take logarithms when computing with ratios.
\item Section 11.2.2 has a couple examples (e.g., beta).
\end{itemize}
\notes{
In step 3 in previous slide's notes, it's often easier (and safer numerically)
to check whether
\[
\log U < \log f(X) - \log K - \log g(X).
\]
}
\end{frame}


\startframe{Monte Carlo methods}
Suppose that 
\begin{itemize}
\item
$f(x)=\alpha r(x)$ and $g(x)=\beta s(x)$ are density functions
\item
$r(x)$ and $s(x)$ are known functions (but $\alpha$ and $\beta$ might be unknown).  
\item
$K=\sup_x r(x)/s(x)$ is finite
and known.  
\item 
Let $X\sim g(x)$ and $U\sim \mbox{unif}(0,1)$ be independent. 
\end{itemize}
\[
\mbox{Then} \quad X \mid U \le \frac{r(X)}{Ks(X)} \sim f.
\]
\notes{
The proof begins by writing 
$P[X\le x \mid U \le \frac{r(X)}{Ks(X)}]$ using the definition of conditional
probability.  Next, use the conditioning technique by conditioning on $X$
in both the numerator and the denominator,
then simplify.  Try it yourself!
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}


