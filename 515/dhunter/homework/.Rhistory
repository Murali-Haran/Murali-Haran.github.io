y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
delta
deltad
deltad2
summary(ergm.update.formula(formulae[[m1]], nw~.))
summary(formulae[[m1]])
summary(ergm.update.formula(formulae[[m1]], nw~.))-summary(formulae[[m1]])
Q
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
q()
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
warnings()
bergmS
bergm
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
deltad
deltad2
Q
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
delta
deltad
deltad2
mstats
mstats2 <- summary(ergm.update.formula(formulae[[m]], nw~.))
mstats2
Q
q()
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
flo.out <- bergmS.output(flo)
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
z
Q
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
z
nw
z
nw
z
nw
z
nw
z
Q
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
flo.out <- bergmS.output(flo)
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
q()
library(Bergm)
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
mstats
mstats2
Q
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
flo.out <- bergmS.output(flo)
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
q()
library(ergm)
?gof
q()
library(Bergm)
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
q()
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
library(Bergm)
data(florentine)#
y <- flomarriage#
#
# Competing models:#
#
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))#
#
# Model selection via auto-RJ exchange algorithm#
# (this  will take about 3.5 minutes)#
flo <- bergmS(formulae,#
              iters=1000,#
              aux.iters=300,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=1500)
debug (bergm)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=1500)
tot.iters
k
nchains
h
k
h
k
h
break
k=2000
k
Q
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=3)
Q
undebug (bergm)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=3)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=3,#
             aux.iters=3000,#
             main.iters=3)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=30,#
             aux.iters=3000,#
             main.iters=30)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=50,#
             aux.iters=3000,#
             main.iters=50)
q*()
q()
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=50,#
             aux.iters=300,#
             main.iters=50)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=50,#
             aux.iters=300,#
             main.iters=150)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=50,#
             aux.iters=3000,#
             main.iters=150)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=150)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=1500)
?simulate.formula
bergm.output(flo)
bgof(flo,#
     n.sim=100,#
     n.deg=10,#
     n.dist=9,#
     n.esp=6)
y <- flomarriage
formulae <- c(y ~ edges, #
              y ~ edges + gwesp(log(2),fixed=TRUE),#
              y ~ edges + gwdegree(log(2),fixed=TRUE))
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
flo.out <- bergmS.output(flo)
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
q()
library(Bergm)
flo <- bergm(flomarriage ~ edges + kstar(2:3),#
             burn.in=500,#
             aux.iters=3000,#
             main.iters=1500)
warnings()
flo <- bergmS(formulae,#
              iters=10000,#
              aux.iters=3000,#
              main.iters=rep(1000,3),#
              burn.in=rep(100,3),#
              gammas=c(0.8,1,1))
warnings()
flo.out <- bergmS.output(flo)
bgof(flo.out,#
     lags=200,#
     n.sim=100,#
     n.deg=10,#
     n.dist=10,#
     n.esp=5)
q()
library(ergm)
q()
?write_PACKAGES
?tools::write_PACKAGES
?download.packages
?url
?install.packages
remove.packages("network")
?tools::write_PACKAGES
help(package="nmle")
remove.packages("Rglpk")
?update
?update.packages
?packageDescription
?parse
?packageDescription
?iconv
?parse
?substr
?strsplit
?grep
?packageDescription
?update.packages
?match
?strsplit
"kjfg"=="kjfg"
?detach
abind
library(network)
abind
q()
abind
library(shapes)
abind
library(abind)
abind
q()
library(statnet)
library(statnet, repos="file:~/repos")
q()
library(statnet)
q()
?install.packages
??ask
?interactive
??input
?scan
a=scan(text="yes or no?")
a=scan(text="yes or no?", what=character())
a=scan(what=character())
a
a=scan(what=character(), nmax=1)
a
a=scan(what=character(), nmax=1, quiet=TRUE)
a
a=scan(what=character(), nmax=1, quiet=TRUE)
a
cat("Type yes or no:");a=scan(what=character(), nmax=1, quiet=TRUE)
a=scan(what=character(), n=1, quiet=TRUE)
a
q()
install.packages("statnet", repos="http:statnet.org")
install.packages("statnet", repos="http:/statnet.org")
install.packages("statnet", repos="http://statnet.org")
install.packages("statnet", repos="http://csde.washington.edu/statnet")
update_statnet()
library(statnet)
update_statnet()
install.packages("statnet", repos="http://csde.washington.edu/statnet")
update_statnet()
library(statnet)
update_statnet()
update_statnet
scan(what=character())
character(0)=="n"
if(logical(0))
NULL
if(logical(0)) {cat("oij")}
detach(package:statnet)
update_statnet()
library(statnet)
update_statnet()
update_statnet
length(character(0))
q()
install.packages("statnet", repos="http://csde.washington.edu/statnet")
library(statnet)
update_statnet
update_statnet()
q()
?install.packages
library(ergm)
install.packages("ergm", repos="http://csde.washington.edu/statnet")
library(ergm)
?write.packages
?write_PACKAGES
?tools::write_PACKAGES
library(statnet)
install.packages("statnet", repos="http://csde.washington.edu/statnet")
library(statnet)
citation("statnet")
install.packages("statnet", repos="http://www.statnet.org")
?url
?regexp
?strsplit
a <- packageDescription("statnet", fields="Depends")#
  b <- unlist( strsplit( a, '[^a-zA-Z.]+'))
b
b <- c(b[b!="R" || b!="."], "statnet")
b
b <- c(b[b!="R" || b!="."], "statnet")
b
b <- c(b[b!="R" && b!="."], "statnet")
b
a <- packageDescription("statnet", fields="Depends")#
  b <- unlist( strsplit( a, '[^a-zA-Z.]+'))
b!="R" || b!="."
b!="R" | b!="."
b!="R" & b!="."
b <- c(b[b!="R" & b!="."], "statnet")
b
?update.packages
q()
install.packages("abind")
install.packages("shapes")
?update.packages
install.packages("mvtnorm")
q()
update.packages(repos="http://csde.washington.edu/statnet")
update.formula
library(statnet)
citation("statnet")
library(mixtools)
install.packages("mixtools")
library(ergm.userterms)
data(fauxhigh)
summary(fauxhigh~mindegree(2)+mymindegree(2))
summary(fauxhigh~mindegree(3)+mymindegree(3))
summary(fauxhigh~mindegree(5)+mymindegree(4))
summary(fauxhigh~mindegree(4)+mymindegree(4))
summary(fauxhigh~mindegree(5)+mymindegree(5))
summary(fauxhigh~mindegree(1)+mymindegree(1))
summary(fauxhigh~mindegree(1:3)+mymindegree(1:3))
x=(8/15)^(0:3)
x
sum(x)
1/sum(x)
p0=1/sum(x)
(8/15)^3*p0
q()
library(ergm)
q()
library(ergm)
library(sna)
data(florentine)
data(florentine)#
ls()#
plot(flomarriage)
plot(1)
library(ergm)
library(ergm.userterms)
data(florentine)
plot(flomarriage)
summary(flomarriage~degree(0:10))
summary(flomarriage~mymindegree)
summary(flomarriage~mymindegree(3))
?ergm.terms
q()
library(statnet)
q()
library(statnet)
det
base::base
base::det
?statnet
?statnet-package
?'statnet-package'
help(package="statnet")
q()
library(ergm)
data(fauxhigh)
?fauxhigh
plot(fauxhigh)
?plot.network
a=plot(fauxhigh, interactive=T)
a
plot(fauxhigh, coord=a)
q()
R = matrix(c(-1,2,1,-2),2,2)
R
eigen(R)
eigen(t(R))
p=c(.5,.5)
p %*% R
R %*% p
eigen(t(R))$vec
eigen(t(R))$vec[,2]
p=.Last.value
p=p/sum(p)
p
q()
library(ergm)
simcoef = function(para,numnodes,numgraphsim,burninv)#
{#
      paran = para/c(1,numnodes)#
      nsuffstatsm=NULL#
      for(i in 1:numgraphsim)#
      {#
              g.use = network(numnodes,density = 0.5, directed = FALSE)#
              print(summary(g.use~edges))#
              net =#
simulate(~edges+triangle,basis=g.use,theta0=paran,burnin=burninv,#
nsim=1,verbose = TRUE,seed = ceiling(1000*runif(1,0,1)))#
              print(summary(net~edges))#
              suffstats=as.vector(summary(net~edges+triangle))#
              nsuffstats=suffstats/c(1,numnodes) #c(1/2,numnodes/6)#
              nsuffstatsm=rbind(nsuffstatsm,nsuffstats)#
      }#
      return(list("nsuffstats" = nsuffstatsm))#
}
simcoef = function(para,numnodes,numgraphsim,burninv)
{
paran = para/c(1,numnodes)
simcoef = function(para,numnodes,numgraphsim,burninv)
{
paran = para/c(1,numnodes)
nsuffstatsm=NULL
for(i in 1:numgraphsim)
{
simcoef = function(para,numnodes,numgraphsim,burninv)
{
paran = para/c(1,numnodes)
nsuffstatsm=NULL
for(i in 1:numgraphsim)
{
g.use = network(numnodes,density = 0.5, directed = FALSE)
print(summary(g.use~edges))
net =
simulate(~edges+triangle,basis=g.use,theta0=paran,burnin=burninv,
nsim=1,verbose = TRUE,seed = ceiling(1000*runif(1,0,1)))
print(summary(net~edges))
suffstats=as.vector(summary(net~edges+triangle))
nsuffstats=suffstats/c(1,numnodes) #c(1/2,numnodes/6)
nsuffstatsm=rbind(nsuffstatsm,nsuffstats)
}
return(list("nsuffstats" = nsuffstatsm))
}
para=c(0.4,0.2)
numnodes=7
numgraphsim=200
burninv=100000
numnodessim=400
r1=simcoef(para,numnodessim,numgraphsim,burninv)
?abind
library(abind)
?abind
?read.table
m=matrix(0,10,11)
abind(m,m,m,m)
?abind
array(m,m,m,m)
?array
m2=rbind(m,m+1,m+2,m+3)
m2
a=array(m2,dim=c(8,10,11))
a
a=array(m2,dim=c(10,11,8))
a
array(m2,dim=c(10,8,11))
array(m2,dim=c(4,10,11))
array(m2,dim=c(10,11,4))
array(m2,dim=c(10,4,11))
m2
array(1:6,1:3)
a=array(m2,dim=c(10,4,11))
a[,2,]
my_80x11_matrix=m2
my_80x11_matrix
q()
library(mixtools)
citation("mixtools")
R <- matrix(1:16, 4, 4); diag(R) <- 0; diag(R) <- -rowSums(R)
R
?rexp
?sample
maxTime <- 10#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, prob=R[currentState,possibleMoves])#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
maxTime <- 10#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
maxTime <- 10#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
X <- list() # Each item in X will consist of TWO vectors:  times and states#
            # Actually, technically, each item will be a list with two elements:#
            # A vector named times and a vector named states.#
#
maxTime <- 10#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
X[[1]]
X <- list() # Each item in X will consist of TWO vectors:  times and states#
            # Actually, technically, each item will be a list with two elements:#
            # A vector named times and a vector named states.#
#
maxTime <- 2#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
X[[1]]
?sapply
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  apply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}
f(X[[1]])
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  sapply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}
f(X[[1]])
deltaTimes = diff(X[[1]]$times)
states <- X[[1]]$states[-length(X[[1]]$states)]
states
deltaTimes
sum(deltaTimes[states==1])
deltaTimes[states==1]
?sample
X <- list() # Each item in X will consist of TWO vectors:  times and states#
            # Actually, technically, each item will be a list with two elements:#
            # A vector named times and a vector named states.#
#
maxTime <- 1 # This is the cutoff time.#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
f(X[[1]])
sum(.Last.value)
maxTime <- 10 # This is the cutoff time.#
for (count in 1:100) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}
f(X[[1]])
sum(.Last.value)
sapply(X, f)
a=.Last.value
dim(a)
colSums(a)
rowMeans(a)
rowMeans(a)/10
eigen(t(R))
pi=eigen(t(R))$vec[,4]
pi=pi/sum(pi)
pi
rowMeans(a)/10
timesPerState <- sapply(X, f)#
#
# If we want, double-check that the total time sums to maxTime for each M.C.:#
all(colSums(timesPerState)==maxTime)  # Should get TRUE if things are okay
rowMeans(timesPerState) / maxTime#
#
# How do these proportions compare with the limiting proportions? #
# The limiting proportions are a left-eigenvector of R having eigenvector#
# zero.  To get left-eigenvectors, just find eigenvectors of t(R):#
e <- eigen(t(R))#
pi <- e$vec[,e$val==0]#
pi <- pi/sum(pi) # Need to standardize#
print(pi)
X <- list() # Each item in X will consist of TWO vectors:  times and states#
            # Actually, technically, each item will be a list with two elements:#
            # A vector named times and a vector named states.#
#
maxTime <- 10 # This is the cutoff time.#
for (count in 1:10000) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}#
#
# Next, we need to summarize the time spent in each state.#
# Define a function that takes a list with named items 'times' and 'states'#
# then returns a vector giving total time spent in each state.#
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  sapply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}#
#
# Next, apply the above function to each of the items in X:#
timesPerState <- sapply(X, f)#
#
# If we want, double-check that the total time sums to maxTime for each M.C.:#
all(colSums(timesPerState)==maxTime)  # Should get TRUE if things are okay#
#
# Calculate the average time spent in each of the four states:#
rowMeans(timesPerState)#
#
# Express the above as a proportion of the total time:#
rowMeans(timesPerState) / maxTime#
#
# How do these proportions compare with the limiting proportions? #
# The limiting proportions are a left-eigenvector of R having eigenvector#
# zero.  To get left-eigenvectors, just find eigenvectors of t(R):#
e <- eigen(t(R))#
pi <- e$vec[,e$val==0]#
pi <- pi/sum(pi) # Need to standardize#
print(pi)
maxTime <- 20 # This is the cutoff time.#
for (count in 1:2000) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}#
#
# Next, we need to summarize the time spent in each state.#
# Define a function that takes a list with named items 'times' and 'states'#
# then returns a vector giving total time spent in each state.#
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  sapply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}#
#
# Next, apply the above function to each of the items in X:#
timesPerState <- sapply(X, f)#
#
# If we want, double-check that the total time sums to maxTime for each M.C.:#
all(colSums(timesPerState)==maxTime)  # Should get TRUE if things are okay#
#
# Calculate the average time spent in each of the four states:#
rowMeans(timesPerState)#
#
# Express the above as a proportion of the total time:#
rowMeans(timesPerState) / maxTime#
#
# How do these proportions compare with the limiting proportions? #
# The limiting proportions are a left-eigenvector of R having eigenvector#
# zero.  To get left-eigenvectors, just find eigenvectors of t(R):#
e <- eigen(t(R))#
pi <- e$vec[,e$val==0]#
pi <- pi/sum(pi) # Need to standardize#
print(pi)
X[[1]]
colSums(timesPerState)[1:10]
all(colSums(timesPerState)==maxTime)
sum(colSums(timesPerState)==maxTime)
sum(colSums(timesPerState)!=maxTime)
X=list()
maxTime <- 20 # This is the cutoff time.#
for (count in 1:2000) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}#
#
# Next, we need to summarize the time spent in each state.#
# Define a function that takes a list with named items 'times' and 'states'#
# then returns a vector giving total time spent in each state.#
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  sapply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}#
#
# Next, apply the above function to each of the items in X:#
timesPerState <- sapply(X, f)#
#
# If we want, double-check that the total time sums to maxTime for each M.C.:#
all(colSums(timesPerState)==maxTime)  # Should get TRUE if things are okay#
#
# Calculate the average time spent in each of the four states:#
rowMeans(timesPerState)#
#
# Express the above as a proportion of the total time:#
rowMeans(timesPerState) / maxTime#
#
# How do these proportions compare with the limiting proportions? #
# The limiting proportions are a left-eigenvector of R having eigenvector#
# zero.  To get left-eigenvectors, just find eigenvectors of t(R):#
e <- eigen(t(R))#
pi <- e$vec[,e$val==0]#
pi <- pi/sum(pi) # Need to standardize#
print(pi)
Here is some code in R that simulates 10000 independent realizations of #
## a 4-state continuous-time Markov chain until time t=1.  We presume that#
## we are given the rate matrix, R, and ultimately we want to find the proportion#
## of the time spent in each of the four states.#
#
# First, let's set up the R matrix (these numbers aren't actually meaningful;#
# this is just an example)#
R <- matrix(1:16, 4, 4); diag(R) <- 0; diag(R) <- -rowSums(R)#
print(R) # Take a look at R#
#
X <- list()  # Each item in X will consist of TWO vectors:  times and states#
             # Actually, technically, each item will be a list with two elements:#
             # A vector named times and a vector named states.#
maxTime <- 1 # This is the cutoff time.#
for (count in 1:10000) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}#
#
# Next, we need to summarize the time spent in each state.#
# Define a function that takes a list with named items 'times' and 'states'#
# then returns a vector giving total time spent in each state.#
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  sapply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}#
#
# Next, apply the above function to each of the items in X:#
timesPerState <- sapply(X, f)#
#
# If we want, double-check that the total time sums to maxTime for each M.C.:#
all(colSums(timesPerState)==maxTime)  # Should get TRUE if things are okay#
#
# Calculate the average time spent in each of the four states:#
rowMeans(timesPerState)#
#
# Express the above as a proportion of the total time:#
rowMeans(timesPerState) / maxTime#
#
# How do these proportions compare with the limiting proportions? #
# The limiting proportions are a left-eigenvector of R having eigenvector#
# zero.  To get left-eigenvectors, just find eigenvectors of t(R):#
e <- eigen(t(R))#
pi <- e$vec[,e$val==0]#
pi <- pi/sum(pi) # Need to standardize#
print(pi)
length(X)
colSums(timesPerState)[1:10]
maxTime
sum(colSums(timesPerState)==maxTime)
colSums(timesPerState)[colSums(timesPerState)!=maxTime]
colSums(timesPerState)[colSums(timesPerState)!=maxTime]-1
all(round(colSums(timesPerState),12)==maxTime)  # Should get TRUE if things are okay
Here is some code in R that simulates 10000 independent realizations of #
## a 4-state continuous-time Markov chain until time t=1.  We presume that#
## we are given the rate matrix, R, and ultimately we want to find the proportion#
## of the time spent in each of the four states.#
#
# First, let's set up the R matrix (these numbers aren't actually meaningful;#
# this is just an example)#
R <- matrix(1:16, 4, 4); diag(R) <- 0; diag(R) <- -rowSums(R)#
print(R) # Take a look at R#
#
X <- list()  # Each item in X will consist of TWO vectors:  times and states#
             # Actually, technically, each item will be a list with two elements:#
             # A vector named times and a vector named states.#
maxTime <- 1 # This is the cutoff time.#
for (count in 1:10000) {#
  times <- 0#
  states <- 1 # Assume that we always start in state 1 at time 0#
  i <- 1 # which time/state are we currently in#
  finished <- FALSE # One way to know when to stop#
  while (!finished) {#
    currentState <- states[i]#
    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    times <- c(times, currentTime + deltaTime)#
    possibleMoves <- (1:4)[-currentState]#
    states <- c(states, sample(possibleMoves, 1, prob=R[currentState,possibleMoves]))#
    i <- i+1#
  }#
  X[[count]] <- list(times=times, states=states)#
}#
#
# Next, we need to summarize the time spent in each state.#
# Define a function that takes a list with named items 'times' and 'states'#
# then returns a vector giving total time spent in each state.#
f <- function(a, nstates=4) { #
  deltaTimes <- diff(a$times)#
  states <- a$states[-length(a$states)] # delete the final state, which is irrelevant#
  sapply(1:nstates, function(b) sum(deltaTimes[states==b]))#
}#
#
# Next, apply the above function to each of the items in X:#
timesPerState <- sapply(X, f)#
#
# If we want, double-check that the total time (rounded to 12 digits, say) #
# sums to maxTime for each M.C.:#
all(round(colSums(timesPerState),12)==maxTime)  # Should get TRUE if things are okay#
#
# Calculate the average time spent in each of the four states:#
rowMeans(timesPerState)#
#
# Express the above as a proportion of the total time:#
rowMeans(timesPerState) / maxTime#
#
# How do these proportions compare with the limiting proportions? #
# The limiting proportions are a left-eigenvector of R having eigenvector#
# zero.  To get left-eigenvectors, just find eigenvectors of t(R):#
e <- eigen(t(R))#
pi <- e$vec[,e$val==0]#
pi <- pi/sum(pi) # Need to standardize#
print(pi)
81 + 2*27 + 4*9 + 8*3 + 16
211/81
211-81
211/13
130/211
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
                       12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         6, 6)#
e <- eigen(t(R))#
pi <- e$vec[, e$val==0]
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
                       12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5,5)#
e <- eigen(t(R))#
pi <- e$vec[, e$val==0]
pi
e
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
                       12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5,5)#
e <- eigen(t(R))#
pi <- e$vec[, e$val==0]
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
                       12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5, 5)#
e <- eigen(t(R))#
pi <- e$vec[, abs(e$val)< 1e-15]
pi
R
e
pi <- pi/sum(pi)
pi
1-pi
81+54+36+24+16
54+2*36 + 3*24 + 4*16
211/7
211/13
211/11
211/17
211/19
262/211
pi
sum(pi*(0:4))
R
m=diag(rep(1,5)) + R/2
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m
k=1
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m
m
k=2
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m
m
k=3
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m
k=3
m
library(Matrix)
expm(R/2)
k=4
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m
m
k=5
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m)
k=6
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m)
k=7
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m)
k=8
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m)
expm(R/2)
k=9
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m)
k=10
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m)
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m-expm(R/2))
k=11
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m-expm(R/2))
k=12
m=diag(rep(1,5)) + R/2/2^k; for(i in 1:k) m=m %*% m; print(m-expm(R/2))
m=solve(diag(rep(1,5)) - R/2/2^k); for(i in 1:k) m=m %*% m; print(m-expm(R/2))
m
rowSums(m)
x=matrix(runif(2e6),ncol=2)
plot(x)
x=matrix(runif(2e4),ncol=2)
plot(x)
sum(apply(x,1,function(a)a[1]^2+a[2]^2<1))
pi/4
3.14159265 / 4
?Random.seed
?Random
16/211
15^(0:4)
8^(0:4)
50625 + 8*3375 + 64*225 + 512*8 + 4096
100217/3
100217-50625
49592/100217
50625 * 8/15
50625 * (8/15)^2
50625 * (8/15)^3
50625 * (8/15)^4
50625 * (8/15)^4 / 100217
8*(0.0758 - 0.0409)
130/211*12
15*49592/100217
4227-3933
f=function(x) (4096/x^4)/(1+8/x+64/x^2+512/x^3+4096/x^4)
f(12)
f(15)
g=function(x) 4096/(x^4+8*x^3+64*x^2+512*x+4096)
g(15)
g=function(x) (x^4+8*x^3+64*x^2+512*x+4096)
g(15)
4096/103801
8*(0.0758 - 0.0395)
103801-50625
15*53176/103801
7.6843 - 7.3933
f(12)
8*(f(15)-f(12))
8*(f(12)-f(15))
8(16/211-4096/103801)
8*(16/211-4096/103801)
15*53176/103801 - 12*130/211
h=function(x) x^4+8*x^3+64*x^2+512*x
h(14)
19*4096
h(13)
h(13.5)
h(13.6)
h(13.7)
h(13.7)-19*4096
h(13.8)-19*4096
h(13.9)-19*4096
h(13.85)-19*4096
h(13.86)-19*4096
h(13.87)-19*4096
h(13.88)-19*4096
h(13.875)-19*4096
h(13.873)-19*4096
h(13.8735)-19*4096
h(13.8731)-19*4096
h(13.8732)-19*4096
h(13.87315)-19*4096
h(13.87316)-19*4096
h(13.873155)-19*4096
h(13.873152)-19*4096
h(13.873153)-19*4096
h(13.8731525)-19*4096
h(13.87315245)-19*4096
h(13.8731524)-19*4096
h(13.87315235)-19*4096
h(13.87315236)-19*4096
h(13.87315235)-19*4096
h(13.87315235)
19*4096
?solve
?optimize
uniroot(function(x) x^4+8*x^3+64*x^2+512*x-19*4096, lower=12, upper=15)
uniroot(function(x) x^4+8*x^3+64*x^2+512*x-19*4096, lower=12, upper=15)$root
f
f=function(a,b,x,y) (b*exp(x-y)+(b-a)*exp(-y)-a*exp(-x-y))/sqrt((1-exp(-x))*(1-exp(-y))*(b+a*exp(-x))*(b+a*exp(-y)))
f(0, 1, log(2), log(4))
f(1, 0, log(2), log(4))
f=function(a,b,x,y) (b*exp(x-y)+(a-b)*exp(-y)-a*exp(-x-y))/sqrt((1-exp(-x))*(1-exp(-y))*(b+a*exp(-x))*(b+a*exp(-y)))
f(0, 1, log(2), log(4))
f(1, 0, log(2), log(4))
q()
x=seq(0,1,len=200)
plot(x,-sqrt(x))
q()
nintegrate
integrate
?integrate
f = function(x) pnorm(x^2) * dnorm(x)
integrate(f, -Inf, Inf)
X = matrix(2e6, ncol=2)
sum(X[,2]<X[,1]^2)
X = matrix(rnorm(2e6), ncol=2)
sum(X[,2]<X[,1]^2)
phat = 719404/1e6
phat
phat + c(-1.96, 1.96) * sqrt(phat*(1-phat)/1e6)
n <- 1e4#
x <- matrix(runif(2*n), ncol=2)#
plot(x) # Take a look at the sampled points#
a <- sum(apply(x, 1, function(a) a[1]^2 + a[2]^2 < 1))#
muhat <- 4*a/n#
# Look at estimate of pi, give confidence interval#
muhat#
muhat + c(-1.96, 1.96) * sqrt(var(muhat)/n)
var(muhat)
Simulating pi example:#
n <- 1e4#
x <- matrix(runif(2*n), ncol=2)#
plot(x) # Take a look at the sampled points#
a <- apply(x, 1, function(a) a[1]^2 + a[2]^2 < 1)#
muhat <- mean(4*a)#
# Look at estimate of pi, give confidence interval#
muhat#
muhat + c(-1.96, 1.96) * sqrt(var(4*a)/n)
length(a)
var(4*a)
sum(a)/n
.7842*(1-.7842)/n
var(4*a)/n
.7842*(1-.7842)*4/n
.7842*(1-.7842)*16/n
Simulating pi example:#
n <- 1e4#
x <- matrix(runif(2*n), ncol=2)#
plot(x) # Take a look at the sampled points#
a <- apply(x, 1, function(a) a[1]^2 + a[2]^2 < 1)#
muhat <- mean(4*a)#
# Look at estimate of pi, give confidence interval#
muhat#
muhat + c(-1.96, 1.96) * sqrt(var(4*a)/n)
n <- 1e4#
x <- matrix(runif(2*n), ncol=2)#
plot(x) # Take a look at the sampled points#
a <- apply(x, 1, function(a) a[1]^2 + a[2]^2 < 1)#
muhat <- mean(4*a)#
# Look at estimate of pi, give confidence interval#
muhat#
muhat + c(-1.96, 1.96) * sqrt(var(4*a)/n)
f <- function(x) pnorm(x^2) * dnorm(x)#
integrate(f, -Inf, Inf)#
n <- 1e6#
X <- matrix(rnorm(2*n), ncol=2)#
successes <- sum(X[,2] < X[,1]^2)#
phat <- successes/n#
phat#
phat + c(-1.96, 1.96) * sqrt(phat*(1-phat)/n)
?integrate
1/sqrt(8)
q()
R=matrix(c(-8,12,0,0,0,8,-20,12,0,0,0,8,-20,12,0,0,0,8,-20,12,0,0,0,8,-12),5,5)#
R
I=diag(n)#
n<-c(5)#
I <- matrix(0,nrow=n,ncol=n)#
I[row(I)==col(I)] <- 1#
I
G<-function(K,k){#
	G<-I+(R*(0.5/k))#
	for(i in 1:k) G<-G%*%G#
}
q()
R = matrix(c(-11, 6, 5, 0,#
             3, -8, 0, 5,#
             2, 0, -8, 6,#
             0, 2, 3, -5), nrow = 4, byrow = TRUE)
P = matrix(c(0, 6/11, 5/11, 0,#
             3/8, 0, 0, 5/8,#
             2/8, 0, 0, 6/8,#
             0, 2/5, 3/5, 0), nrow = 4, byrow = TRUE)
state = 1:4; N = 10000; count = 0;
stateresult = list(NULL); timeresult = list(NULL)
for(m in 1:N){#
chain = time = c(); chain[1] = 1; time[1] = 0;#
n = 1; T = 0;#
while(T < 1.5){#
n = n + 1;#
time[n] = rexp(1, rate = abs(R[chain[n-1], chain[n-1]]));#
T = T + time[n];#
chain[n] = sample(state, size = 1, prob = P[chain[n-1], ])#
		}#
count = count + (chain[n] == 4)#
stateresult[[m]] = chain; timeresult[[m]] = time; #
		}
count
length(stateresult)
stateresult[[1]]
timeresult[[1]]
cumsum(.Last.value)
table(sapply(stateresult, function(a) a[length(a)]))
table(sapply(stateresult, function(a) a[length(a)-1]))
R
P
e=eigen(t(P))
e
pi=e$vec[,2]
pi=pi/sum(pi)
pi
pi * P
pi %*% P
pi
library(Matrix)
expm(R)
expm(R*1.5)
pi2=expm(R*1.5)[1,]
pi2
pi2 %*% P
table(sapply(stateresult, function(a) a[length(a)]))/10000
expm(1.5*R)[1,] %*% P
expm(1.5*R)
expm(15*R)
expm(.0015*R)
expm(1.5*R)
expm(.5*R)
expm(.25*R)
??object.size
??memory
?object.size
ls()
object.size(stateresult)
stateresult[[1]]
stateresult[[5]]
library(ergm)
ls()
object.size(ergm(flobusiness~edges + isolate))
object.size(ergm(flobusiness~edges + isolates))
effectiveSize
lapply(ergm, object.size)
object.size(a<-ergm(flobusiness~edges + isolates))
lapply(a, object.size)
sort(unlist(lapply(a, object.size)))
sort(unlist(lapply(a$initialfit, object.size)))
?system.time
q()
library(mixtools)
?logdmvnorm
?dnorm
length(NULL)
dmvnorm(c(0:2),mu=0)
?Waterdata
?uniroot
Finv = function(u) uniroot(function(a,u) 3*x^4-4*x^3+u, 0:1, u=u)$root
Finv(.2)
Finv = function(u) uniroot(function(a,u) 3*x^4-4*x^3+u, interval=0:1, u=u)$root
Finv(.2)
Finv = function(u) uniroot(function(a,u) 3*a^4-4*a^3+u, interval=0:1, u=u)$root
Finv(.2)
Finv(.5)
sapply(runif(10), Finv)
x=sapply(runif(1e2), Finv)
x=sapply(runif(1e3), Finv)
x=sapply(runif(1e4), Finv)
x=sapply(runif(1e5), Finv)
x=sapply(runif(1e6), Finv)
hist(x, prob=T)
lines(function(a) 12*x^2*(1-x))
xx=seq(0,1,len=200)
lines(xx,12*xx^2*(1-xx))
F <- function(x) x^3#
FminusU <- function(x, u) F(x) - u#
Finv <- function(u) uniroot(FminusU, interval=c(0,1), u=u)$root#
#
# Now generate a lot of uniforms and apply Finv to them:#
u <- runif(1e5)#
system.time (x <- sapply(u, Finv))  # use system.time to see how long it takes
hist(x)
?hist
hist(x, freq=FALSE)#
xx <- seq(0, 1, len=200)#
lines(xx, 2 * xx^2, col=2)
hist(x, freq=FALSE)#
xx <- seq(0, 1, len=200)#
lines(xx, 3 * xx^2, col=2)
?svd
Sigma = matrix(c(4, 4, 4, 9), 2,2)
Sigma
svd(Sigma)
?qr
qr(Sigma)
mu <- c(1, -2)#
Sigma <- matrix(c(16, -5, 5, 25), 2, 2)#
#
# Now use the svd to find X such that X %*% t(X) equals Sigma:#
svd.Sigma <- svd(Sigma)#
X <- svd.Sigma$u %*% diag(sqrt(svd.Sigma$d)) %*% t(svd.Sigma$v)#
#
# Verify that it worked:#
X %*% t(X)
svd.Sigma
Sigma
mu <- c(1, -2)#
Sigma <- matrix(c(16, -5, 5, 25), 2, 2)#
#
# Now use the svd to find X such that X %*% t(X) equals Sigma:#
svd.Sigma <- svd(Sigma)#
X <- svd.Sigma$u %*% diag(sqrt(svd.Sigma$d)) %*% svd.Sigma$v#
#
# Verify that it worked:#
X %*% t(X)
attach(svd.Sigma)
u %*% diag(d) %*% t(v)
u
svd.Sigma$u %*% diag(d) %*% t(v)
svd.Sigma
?eigen
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- t(e$vec) $ sqrt(e$val)
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- t(e$vec) * sqrt(e$val)
X %*% t(X)
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- (e$vec) * sqrt(e$val)
X %*% t(X)
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- (e$vec) * diag(sqrt(e$val))
X %*% t(X)
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- t(e$vec) * diag(sqrt(e$val))
X %*% t(X)
e$ vec %*% t(e$vec)
e$ vec %*% (t(e$vec)* sqrt(e$val)
)
X=e$ vec %*% (t(e$vec)* sqrt(e$val))
X %*% t(X)
Define the mu vector and Sigma matrix:#
mu <- c(1, -2)#
Sigma <- matrix(c(16, -5, 5, 25), 2, 2)#
#
# Now use the eigen decomposition to find X such that X %*% t(X) equals Sigma:#
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- e$vec %*% (t(e$vec) * sqrt(e$val)) #
#
# Verify that it worked:#
X %*% t(X)
mu <- c(1, -2)#
Sigma <- matrix(c(16, -5, 5, 25), 2, 2)#
#
# Now use the eigen decomposition to find X such that X %*% t(X) equals Sigma:#
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- e$vec %*% (t(e$vec) * sqrt(e$val)) #
#
# Verify that it worked:#
X %*% t(X)#
#
# Now multiply X by a lot of columns of standard normals and add mu:#
Y <- X %*% matrix(rnorm(2e4), nrow=2) + mu#
#
# Here is a plot of the result:#
plot(t(Y))
mu <- c(1, -2)#
Sigma <- matrix(c(16, -15, 15, 25), 2, 2)#
#
# Now use the eigen decomposition to find X such that X %*% t(X) equals Sigma:#
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- e$vec %*% (t(e$vec) * sqrt(e$val)) #
#
# Verify that it worked:#
X %*% t(X)#
#
# Now multiply X by a lot of columns of standard normals and add mu:#
Y <- X %*% matrix(rnorm(2e4), nrow=2) + mu#
#
# Here is a plot of the result:#
plot(t(Y))
pnorm(-4.5)
q()
mu <- c(0, 0)#
Sigma <- matrix(c(4,4,4,9), 2, 2)#
#
# Now use the eigen decomposition to find X such that X %*% t(X) equals Sigma:#
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- e$vec %*% (t(e$vec) * sqrt(e$val)) #
#
# Verify that it worked:#
X %*% t(X)#
#
# Now multiply X by a lot of columns of standard normals and add mu:#
Y <- X %*% matrix(rnorm(2e4), nrow=2) + mu#
#
# Here is a plot of the result:#
plot(t(Y))
A=matrix(X %*% matrix(rnorm(2*n), nrow=2) + mu,ncol=2)
n=1e5
A=matrix(X %*% matrix(rnorm(2*n), nrow=2) + mu,ncol=2)
plot(A)
dim(A)
A[1:10,]
A=matrix(A, nrow=2)
plot(t(A))
library(ergm)
data(fauxhigh)
example(ergm)
install.packages("statnet", repos="http://www.csde.washington.edu/statnet")
?install.packages
q()
u = matrix(runif(5e5), ncol=5)
x=apply(u, 1, function(a) sum(a[1:2])/sum(a))
hist(x, freq=F)
x=apply(u, 1, function(a) log(prod(a[1:2]))/log(prod((a)))
)
x=apply(u, 1, function(a) log(prod(a[1:2]))/log(prod(a))
)
hist(x, freq=F)
mean(x)
hist(x, freq=F); lines(xx, dbeta(xx, 2, 3), col=2)
xx=seq(0,1,len=200)
hist(x, freq=F); lines(xx, dbeta(xx, 2, 3), col=2)
x=apply(u, 1, function(a) log(prod(a[1:3]))/log(prod(a)))
hist(x, freq=F); lines(xx, dbeta(xx, 2, 3), col=2)
hist(x, freq=F); lines(xx, dbeta(xx, 3, 2), col=2)
pnorm(-4.5)
mean(rnorm(1e6)>4.5)
phat=mean(rnorm(1e6)>4.5); phat + c(-1.96, 1.96)*sqrt(phat*(1-phat)/1e6)
x=rexp(1e4)
x=rexp(1e4)+4.5
mean(dnorm(x)/exp(4.5-x))
K = 4.5
x=rexp(1e4)+K ; mean(dnorm(x)/exp(K-x))
x=rexp(1e5)+K ; mean(dnorm(x)/exp(K-x))
K=3
x=rexp(1e5)+K ; mean(dnorm(x)/exp(K-x))
x=rexp(1e5)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
K=2
x=rexp(1e5)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
K=1
x=rexp(1e5)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
x=rexp(1e6)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
K=4.5
x=rexp(1e6)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
K=5
x=rexp(1e6)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
K=4.5
x=rexp(1e6)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
f=function(x) exp(-x^2/2)
x=rexp(1e6)+K ; mean(f(x)*(x>4.5)/exp(K-x)) / mean(f(x)/exp(K-x))
K=1
x=rexp(1e6)+K ; mean(f(x)*(x>4.5)/exp(K-x)) / mean(f(x)/exp(K-x))
K=0
x=rexp(1e6)+K ; mean(f(x)*(x>4.5)/exp(K-x)) / mean(f(x)/exp(K-x))
K
K=4.5
x=rexp(1e6)+K ; mean(dnorm(x)*(x>4.5)/exp(K-x))
a=dnorm(x)*(x>4.5)/exp(K-x)
plot(cumsum(a), 1:1e6)
mean(a)
mean(a[1:1000])
mean(a[1:2000])
plot(cumsum(a)/(1:1e6), type="l")
plot((cumsum(a)/(1:1e6))[1:1000], type="l")
plot((cumsum(a)/(1:1e6))[1:10000], type="l")
lgamma
?Deprecated
ddirichlet <- function (x, alpha)#
{#
   if (length(x) != length(alpha))#
	stop("Mismatch between dimensions of x and alpha in ddirichlet().\n")#
       logD <- sum(lgamma(alpha)) - lgamma(sum(alpha))#
       s <- sum((alpha - 1) * log(x))#
       pd <- exp(sum(s) - logD)#
	  pd[any(x < 0 | x > 1)] <- 0#
	  if(sum(x) != 1) pd <- 0#
	  return(pd)#
}
x=runif(5)
x=x/sum(x)
log(ddirichlet(x,1:5))
a=1:5
sum(lgamma(a) + (a-1)*log(x)) -#
lgamma(sum(a))
sum(-lgamma(a) + (a-1)*log(x)) +#
lgamma(sum(a))
library(mixtools)
example(bootse)
example(boot.se)
warnings()
example(logisregmix.init)
example(logisregmixEM)
warnings()
example(multmixEM)
example(gammamixEM)
example(mvnormalmixEM)
m = matrix(rnorm(4),2,2)
sd(m)
example(normalmixEM)
example(poisregmixEM)
example(regmixEM)
example(regmixEM.chgpt)
example(regmixEM.lambda)
example(regmixEM.loc)
example(regmixEM.mixed)
example(repnormmixEM)
example(CO2data)
example(HabituationData)
example(Habituationdata)
example(NOdata)
example(RTdata)
example(RTdata2)
example(RanEffdata)
example(RodFramedata)
example(Waterdata)
example(boot.comp)
example(boot.se)
example(compCDF)
example(density.npEM)
example(density.spEM)
example(depth)
example(dmvnorm)
example(ellipse)
example(flaremixEM)
example(gammamixEM)
example(hmeEM)
example(initializations)
example(ise.npEM)
example(lambda)
example(lambda.pert)
?lambda.pert
lambda.pert
example(ldmult)
example(makemultdata)
example(matsqrt)
matsqrt
example(multimixmodel.sel)
example(multimixmodel)
example(npEM)
example(npMSL)
example(plot.MCMC)
example(plot.mixEM)
example(plot.npEM)
example(poisregmixEM)
example(post.beta
)
example(print.npEM)
example(regcr)
warnings()
example(regmixMH)
warnings()
example(repmixnoremEM
)
example(repnormmixEM)
warnings()
example(rmvnorm)
example(rmvnormmix)
warnings()
example(rnormmix)
example(spEM)
example(spEMsymloc)
warnings()
example(spregmix)
warnings()
example(summary.mixEM)
example(summary.npEM)
example(test.equality)
example(test.equality.mixed)
example(tonedata)
example(try.flare)
example(wkde)
example(wquantile)
example(repnormmixmodel.sel)
?repnormmixmodel.sel
m
m=matrix(runif(4),2,2)
m=matrix(1:4,2,2)
m
mean(m)
16/211
16/211 * 8
16/211 * 8 * 8
?dnorm
q()
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
             12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5, 5)  # Set up the transition matrix#
T <- rep(0, 10000) # This is where we'll store time in state 5#
L <- rep(0, 10000) # This is where we'll store number of lost customers#
maxTime <- 8 # This is the cutoff time.#
for (count in 1:10000) {#
  currentState <- 1#
  currentTime <- 0#
  finished <- FALSE # We'll set this to TRUE when it's time to stop.#
  while (!finished) {#
#    currentState <- states[i]#
#    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    if (currentState == 5) {#
      T[count] <- T[count] + deltaTime#
      L[count] <- L[count] + rpois(1, 8*deltaTime)#
    }#
  }#
cat(" ",count)}
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
             12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5, 5)  # Set up the transition matrix#
T <- rep(0, 10000) # This is where we'll store time in state 5#
L <- rep(0, 10000) # This is where we'll store number of lost customers#
maxTime <- 8 # This is the cutoff time.#
for (count in 1:10000) {#
print(count)#
  currentState <- 1#
  currentTime <- 0#
  finished <- FALSE # We'll set this to TRUE when it's time to stop.#
  while (!finished) {#
#    currentState <- states[i]#
#    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    if (currentState == 5) {#
      T[count] <- T[count] + deltaTime#
      L[count] <- L[count] + rpois(1, 8*deltaTime)#
    }#
    currentTime <- currentTime + deltaTime#
    possibleMoves <- (1:4)[-currentState]#
    currentState <- sample(possibleMoves, 1, prob=R[currentState,possibleMoves])#
  }#
}
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
             12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5, 5)  # Set up the transition matrix#
T <- rep(0, 10000) # This is where we'll store time in state 5#
L <- rep(0, 10000) # This is where we'll store number of lost customers#
maxTime <- 8 # This is the cutoff time.#
for (count in 1:10000) {#
  currentState <- 1#
  currentTime <- 0#
  finished <- FALSE # We'll set this to TRUE when it's time to stop.#
  while (!finished) {#
#    currentState <- states[i]#
#    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    if (currentState == 5) {#
      T[count] <- T[count] + deltaTime#
      L[count] <- L[count] + rpois(1, 8*deltaTime)#
    }#
    currentTime <- currentTime + deltaTime#
    possibleMoves <- (1:4)[-currentState]#
    currentState <- sample(possibleMoves, 1, prob=R[currentState,possibleMoves])#
  }#
}
mean(L)
table(L)
table(T)
R <- matrix(c(-8, 12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -20, #
             12, 0, 0, 0, 8, -20, 12, 0, 0, 0, 8, -12),#
         5, 5)  # Set up the transition matrix#
T <- rep(0, 10000) # This is where we'll store time in state 5#
L <- rep(0, 10000) # This is where we'll store number of lost customers#
maxTime <- 8 # This is the cutoff time.#
for (count in 1:10000) {#
  currentState <- 1#
  currentTime <- 0#
  finished <- FALSE # We'll set this to TRUE when it's time to stop.#
  while (!finished) {#
#    currentState <- states[i]#
#    currentTime <- times[i]#
    deltaTime <- rexp(1, rate = -R[currentState, currentState])#
    if (currentTime + deltaTime > maxTime) {#
      # Now we need to finish this chain#
      deltaTime <- maxTime - currentTime#
      finished <- TRUE#
    }#
    if (currentState == 5) {#
      T[count] <- T[count] + deltaTime#
      L[count] <- L[count] + rpois(1, 8*deltaTime)#
    }#
    currentTime <- currentTime + deltaTime#
    possibleMoves <- (1:5)[-currentState]#
    currentState <- sample(possibleMoves, 1, prob=R[currentState,possibleMoves])#
  }#
}
mean(L)
mean(8*T)
var(L)
var(8*T)
??"repeat"
??"replicate"
??"repeat"
?for
()
??"for"
?'for'
?list
??"loops"
??"loop"
??"for loop"
??"forloop"
a <- array(rnorm(1e5 * 30* 2), c(1e5, 30, 2))#
rhoHat <- apply(a, 1, cor)
length(rhoHat)
a[1,,]
cor(.Last.val)
cor(a[1,,])
cor(a[1,,1],a[1,,2])
?cor
a <- array(rnorm(1e5 * 30* 2), c(1e5, 30, 2))#
f <- function(x) cor(x[,1], x[,2])#
rhoHat <- apply(a, 1, f)
length(rhoHat)
mean(rhoHat>.3)
pval <- mean(rhoHat >= 0.3)#
pval + c(-1.96, 1.96) * sqrt(pval * (1-pval) / 1e5)
2.58/.001
2580^2
qnorm(.005)
Sigma <- matrix(c(4, 4, 4, 9), 2, 2)#
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- e$vec %*% (t(e$vec) * sqrt(e$val)) #
n <- 7e6#
Y <- X %*% matrix(rnorm(2*n), nrow=2)#
phat <- mean(apply(Y, 2, function(x) all(abs(x)<1))#
phat + c(-1,1) * qnorm(.995) * sqrt(phat * (1-phat) / n)
Sigma <- matrix(c(4, 4, 4, 9), 2, 2)#
e <- eigen (Sigma, symmetric=TRUE) # The algorithm is slightly more efficient#
                                   # if symmetric=TRUE is given.#
X <- e$vec %*% (t(e$vec) * sqrt(e$val)) #
n <- 7e6#
Y <- X %*% matrix(rnorm(2*n), nrow=2)#
phat <- mean(apply(Y, 2, function(x) all(abs(x)<1)))#
phat + c(-1,1) * qnorm(.995) * sqrt(phat * (1-phat) / n)
dim(Y)
f=function(x) all(abs(x)<1)
f[Y[,1]]
f(Y[,1])
f(Y[,2])
system.time(phat <- mean(apply(Y, 2, function(x) all(abs(x)<1))))
system.time(phat <- mean(apply(Y, 2, function(x) ))
Linf <- apply(abs(Y), 2, pmax)
z <- abs(Y[1,]) < 1
z2 <- abs(Y[2,]) < 1
mean(z & z2)
phat <- mean( abs(Y[1,]) < 1 & abs(Y[2,]) < 1)#
phat + c(-1,1) * qnorm(.995) * sqrt(phat * (1-phat) / n)
diff(.Last.value)
phat
q()
setwd("dhunter/svn/signednet/ePinion_code_and_data/")
dir()
setwd("revisedDataZipFiles/")
dir()
setwd("estimates1000")
getwd()
setwd("../estimates1000/")
files = list.files(pattern="parameters*")
numClasses = 5#
estimates = matrix(ncol=numClasses,nrow=length(files),0)#
row = 0#
for (file in files) {#
	data = scan(file,nlines=1,skip=2)#
	row = row + 1#
	estimates[row,] = t(data)#
}
tau = read.table(file="Tau.txt")#
class = as.vector(apply(tau, 1, which.max))
freq = table(class)#
groupSize = matrix(0,nrow=1,ncol=numClasses)#
for (k in 1:dim(freq))#
	groupSize[as.integer(names(freq[k]))] =freq[[k]]
trustExcess = read.table(file="trustExcess.txt", sep=",")#
trustExcess = t(trustExcess)#
trustExcess = trustExcess[1:131827,1]
groupTrustExcess = matrix(0,nrow=1,ncol=numClasses)#
for (k in 1:numClasses) #
	groupTrustExcess[k] = sum(trustExcess[class == k]) / groupSize[k]#
ordering =rank(-groupTrustExcess)
arrangedEstimates = matrix(ncol=numClasses,nrow=length(files),0)#
for (k in 1:numClasses) #
	arrangedEstimates[,ordering[k]] = estimates[,k]
library(sfsmisc)
thetahat=c(-6.2557786902, -15.2123791090, -7.6578079343, -9.3425377010,#
  -11.9136589426)[c(1,3,4,5,2)]
postscript(file="GroupExcess.ps")#
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
dev.off()
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=round(thetahat,2), col=1:5, lty=1:5, )
?legend
?plot.math
?plotmath
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=paste(expression(hat(theta)=),round(thetahat,2)), #
   col=1:5, lty=1:5, main="")
legend("topright", legend=paste(expression(hat(theta)),round(thetahat,2)), #
   col=1:5, lty=1:5, main="")
legend("topright", legend=paste(expression(hat(theta))), #
   col=1:5, lty=1:5, main="")
legend("topright", legend=paste(expression(hat(theta))), #
   col=1:5, lty=1:5)
legend("topright", legend=expression(hat(theta)), #
   col=1:5, lty=1:5, main="")
legend("topright", legend=expression(hat(theta)), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=expression(hat(theta)), #
   col=1:5, lty=1:5, main="")
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=expression(hat(theta)), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=paste(expression(hat(theta)), '"'), #
   col=1:5, lty=1:5)
legend("topright", legend=expression(paste(hat(theta)), '"'), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=expression(paste(hat(theta)), '"'), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=expression(paste(hat(theta), '=')), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=expression(paste(hat(theta), '=', round(thetahat,2))), #
   col=1:5, lty=1:5)
a=expression(hat(theta))
a
paste(a, thetahat)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- expression(hat(theta))#
legend("topright", legend=paste(a, '=', round(thetahat,2)), #
   col=1:5, lty=1:5)
plot(1:10, type="n", xlab="", ylab="", main = "plot math & numbers")
theta <- 1.23 ; mtext(bquote(hat(theta) == .(theta)), line= .25)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=bquote(hat(theta) == .(round(thetahat[1],2))), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=bquote(hat(theta) == -.(round(-thetahat[1],2))), #
   col=1:5, lty=1:5)
plot(1:10, type="n", xlab="", ylab="", main = "plot math & numbers")#
theta <- 1.23 ; mtext(bquote(hat(theta) == .(theta)), line= .25)#
for(i in 2:9)#
    text(i,i+1, substitute(list(xi,eta) == group("(",list(x,y),")"),#
                           list(x=i, y=i+1)))#
## note that both of these use calls rather than expressions.#
###
text(1,10,  "Derivatives:", adj=0)#
text(1,9.6, expression(#
 "             first: {f * minute}(x) " == {f * minute}(x)), adj=0)#
text(1,9.0, expression(#
 "     second: {f * second}(x) "        == {f * second}(x)), adj=0)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=paste(bquote(hat(theta) == -), bquote(.(round(-thetahat[1],2)))), #
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
    ),#
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=list(#
    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
    ),#
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=#
    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- bquote(hat(theta) == -.(round(-thetahat[1],2))) #
legend("topright", legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- bquote(hat(theta) == -.(round(-thetahat[1],2))) #
legend("topright", legend=c(a),#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
?legend
plot.new(); plot.window(c(0,4), c(15,1))#
text(1, 1, "universal", adj=0); text(2.5, 1,  "\\042")#
text(3, 1, expression(symbol("\042")))#
text(1, 2, "existential", adj=0); text(2.5, 2,  "\\044")#
text(3, 2, expression(symbol("\044")))#
text(1, 3, "suchthat", adj=0); text(2.5, 3,  "\\047")#
text(3, 3, expression(symbol("\047")))#
text(1, 4, "therefore", adj=0); text(2.5, 4,  "\\134")#
text(3, 4, expression(symbol("\134")))#
text(1, 5, "perpendicular", adj=0); text(2.5, 5,  "\\136")#
text(3, 5, expression(symbol("\136")))#
text(1, 6, "circlemultiply", adj=0); text(2.5, 6,  "\\304")#
text(3, 6, expression(symbol("\304")))#
text(1, 7, "circleplus", adj=0); text(2.5, 7,  "\\305")#
text(3, 7, expression(symbol("\305")))#
text(1, 8, "emptyset", adj=0); text(2.5, 8,  "\\306")#
text(3, 8, expression(symbol("\306")))#
text(1, 9, "angle", adj=0); text(2.5, 9,  "\\320")#
text(3, 9, expression(symbol("\320")))#
text(1, 10, "leftangle", adj=0); text(2.5, 10,  "\\341")#
text(3, 10, expression(symbol("\341")))#
text(1, 11, "rightangle", adj=0); text(2.5, 11,  "\\361")#
text(3, 11, expression(symbol("\361")))
i=3
substitute(list(xi,eta) == group("(",list(x,y),")"),#
                           list(x=i, y=i+1))
substitute(list(xi,eta) == group("(",list(x),")"),#
                           list(x=thetahat[1]))
substitute(list(xi,eta) == group("(",list(x),")"),#
                           list(x=round(thetahat,2))
)
substitute(list(xi,eta) == group("(",list(x),")"),#
                           list(x=round(thetahat,2)))
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- bquote(hat(theta) == -.(round(-thetahat[1],2))) #
legend("topright", legend=#
substitute(list(xi,eta) == group("(",list(x),")"),#
                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- bquote(hat(theta) == -.(round(-thetahat[1],2))) #
legend("topright", legend=#
substitute(list(hat(theta)) == group("(",list(x),")"),#
                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
?substitute
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- bquote(hat(theta) == -.(round(-thetahat[1],2))) #
legend("topright", legend=list(1,2,3),#
#substitute(list(hat(theta)) == group("(",list(x),")"),#
#                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2))))
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
a <- bquote(hat(theta) == -.(round(-thetahat[1],2))) #
legend("topright", legend=#
sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2)))),#
#list(1,2,3),#
#substitute(list(hat(theta)) == group("(",list(x),")"),#
#                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2))))
mtext(.Last.value[[1]])
sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2))))
legend("topleft", legend=.Last.value)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=round(thetahat,2),#
#sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2)))),#
#list(1,2,3),#
#substitute(list(hat(theta)) == group("(",list(x),")"),#
#                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
year1 = 2001#
year2 = 2005#
g1 = 1.9#
g2 = 1.7#
plot(1)#
legend('top',#
        legend=c(#
                as.expression(substitute(paste(year, ': ', gamma, '=', g),#
list(year=year1, g=g1))),#
                as.expression(substitute(paste(year, ': ', gamma, '=', g),#
list(year=year2, g=g2)))#
        )#
)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
   as.expression(bquote(hat(theta) == -.(round(-thetahat[1],2))))#
),#
##
#round(thetahat,2),#
#sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2)))),#
#list(1,2,3),#
#substitute(list(hat(theta)) == group("(",list(x),")"),#
#                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
   as.expression(bquote(hat(theta) == -.(round(-thetahat[1],2)))),#
   as.expression(bquote(hat(theta) == -.(round(-thetahat[2],2))))#
),#
##
#round(thetahat,2),#
#sapply(1:5, function(a) bquote(hat(theta)== -.(round(-thetahat[a],2)))),#
#list(1,2,3),#
#substitute(list(hat(theta)) == group("(",list(x),")"),#
#                            list(x=round(thetahat,2))),#
#legend=a,#
#    bquote(hat(theta) == -.(round(-thetahat[1],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[2],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[3],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[4],2))), #
#    bquote(hat(theta) == -.(round(-thetahat[5],2)))#
#    ),#
   col=1:5, lty=1:5)
?legend
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[1],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[2],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[3],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[4],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[5],2))))#
   ),#
   col=1:5, lty=1:5, cex=2)
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[1],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[2],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[3],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[4],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[5],2))))#
   ),#
   col=1:5, lty=1:5, cex=1.5, lwd=3)
postscript(file="GroupExcess.ps")#
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[1],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[2],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[3],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[4],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[5],2))))#
   ),#
   col=1:5, lty=1:5, cex=1.5, lwd=3)#
dev.off()
getwd()
postscript(file="GroupExcess.ps")#
par(mfrow=c(1,1))#
first <- 2#
	plot(density(arrangedEstimates[,first]-thetahat[first]), xlim=c(-.02,.02), #
	lwd=3, lty=first, cex.axis=2, cex.lab=2, xlab="", ylab="", #
	main="", bty="l", col=first)#
for (k in 1:5[-first]) {#
	lines(density(arrangedEstimates[,k]-thetahat[k]), lwd=3, lty=k, col=k)#
}#
legend("topright", legend=c(#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[1],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[2],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[3],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[4],2)))),#
    as.expression(bquote(hat(theta) == -.(round(-thetahat[5],2))))#
   ),#
   col=1:5, lty=1:5, cex=2, lwd=3)#
dev.off()
1-pnorm(4.5)
log(4)
?write
d=read.table("http://www.astrostatistics.psu.edu/datasets/GRB_afterglow.dat",skip=1,head=T)
dim(d)
d[1:5,]
plot(log(t), f)
plot(log(d$t), d$f)
plot(log(d$t), log(d$f))
getwd()
setwd("../../../.."
)
getwd()
setwd("515/")
ls
dir()
setwd("homework/")
set.seed(123); write(1.6 + rnorm(100), file="hw11prob1b.txt")
set.seed(321); y = c(rpois(35, 16), rpois(15, 22))#
  write(cbind(Time=1:50, Counts=y), file="hw11prob2.txt")
?write
set.seed(321); y = c(rpois(35, 16), rpois(15, 22))#
  write.table(cbind(Time=1:50, Counts=y), file="hw11prob2.txt")
set.seed(321); y = c(rpois(35, 16), rpois(15, 22))#
   write.table(cbind(1:50, y), row.names=F, col.names=c("Time", "Count"), file="hw11prob2.txt")
set.seed(321); y = c(rpois(35, 16), rpois(15, 22))#
   write.table(cbind(1:50, y), row.names=F, col.names=c('Time', 'Count'), file="hw11prob2.txt")
set.seed(321); y = c(rpois(35, 16), rpois(15, 22))#
   write.table(cbind(1:50, y), row.names=F, col.names=c('Time', 'Count'), quote=F, file="hw11prob2.txt")
plot(y)
lines(lowess(y))
set.seed(321); y = c(rpois(35, 16), rpois(15, 22))#
   write.table(cbind(1:50, y), row.names=F, col.names=c("Time", "Count"), quote=F, file="hw11prob2.txt")
f <- function(k) {#
  muhat <- 1:5#
  for (i in 1:5) {#
    x <- rnorm(1e5) + k#
    b <- exp((x-k)^2/2 - x^2/2)#
    a <- (x>4.5)*b#
    muhat[i] <- mean(a) / mean(b)#
  }#
}
f <- function(k) {#
  muhat <- 1:5#
  for (i in 1:5) {#
    x <- rnorm(1e5) + k#
    b <- exp((x-k)^2/2 - x^2/2)#
    a <- (x>4.5)*b#
    muhat[i] <- mean(a) / mean(b)#
  }#
}
f <- function(k) {#
  muhat <- 1:5#
  for (i in 1:5) {#
    x <- rnorm(1e5) + k#
    b <- exp((x-k)^2/2 - x^2/2)#
    a <- (x>4.5)*b#
    muhat[i] <- mean(a) / mean(b)#
  }#
muhat}
f(0)
f(4.5)
x=rnorm(1e5)+4.5
mean((x>4.5)*dnorm(x)/dnorm(x-4.5))
x=rnorm(1e5)+4.5
mean((x>4.5)*dnorm(x)/dnorm(x-4.5))
qnorm(-4.5)
pnorm(-4.5)
f <- function(k) {#
  muhat <- 1:10#
  for (i in 1:10) {#
    x <- rnorm(1e5) + k#
    b <- exp((x-k)^2/2 - x^2/2)#
    a <- (x>4.5)*b#
    muhat[i] <- mean(a) / mean(b)#
  }#
muhat}
sapply(0:9, function(a) sd(f(a/2)))
sapply((0:9)/2, function(a) sd(f(a)))
sapply((0:9)/2, function(a) sd(f(a)))#
(0:9)/2[which.min(.Last.value)] # Which value gave the smallest StDev?
sapply((0:9)/2, function(a) sd(f(a)))
which.min(.Last.value)
sapply((0:9)/2, function(a) sd(f(a)))#
((0:9)/2)[which.min(.Last.value)] # Which value gave the smallest StDev?
sapply((0:9)/2, function(a) sd(f(a)))#
((0:9)/2)[which.min(.Last.value)] # Which value gave the smallest StDev?
mu <- 1-pnorm(4.5)#
sapply((0:9)/2, function(a) mean((f(a)-mu)^2))#
((0:9)/2)[which.min(.Last.value)] # Which value gave the smallest mean squared error?
mu <- 1-pnorm(4.5)#
sapply((0:9)/2, function(a) mean((f(a)-mu)^2))#
((0:9)/2)[which.min(.Last.value)] # Which value gave the smallest mean squared error?
mu <- 1-pnorm(4.5)#
sapply((0:9)/2, function(a) mean((f(a)-mu)^2))#
((0:9)/2)[which.min(.Last.value)] # Which value gave the smallest mean squared error?
mu <- 1-pnorm(4.5)#
sapply((0:9)/2, function(a) mean((f(a)-mu)^2))#
((0:9)/2)[which.min(.Last.value)] # Which value gave the smallest mean squared error?
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- c(1, -muhat)#
  cbind(muhat=muhat, var=v %*% cov(a,b) %*% v / (n*mean(b)^2)#
}
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- c(1, -muhat)#
  cbind(muhat=muhat, var=v %*% cov(a,b) %*% v / (n*mean(b)^2))#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- c(1, -muhat)#
  cbind(muhat=muhat, var=v %*% cov(cbind(a,b)) %*% v / (n*mean(b)^2))#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- c(1, -muhat)#
  cbind(muhat=muhat, var=v %*% cov(cbind(a,b)) %*% v / (n*mean(b)^2))#
}
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- c(1, -muhat)#
  cbind(muhat=muhat, var=v %*% cov(cbind(a,b)) %*% v / (n*mean(b)^2));cbind(mu=muhat, var=2)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- c(1, -muhat)#
  cbind(muhat=muhat, var=(v %*% cov(cbind(a,b)) %*% v / (n*mean(b)^2)))#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, var=v)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, var=2)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  var <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, var=var)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, var=v)#
}
?cbind
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, v=v)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat, v)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat, v, muhat)#
}
f2(2)
muhat=1
v=2
cbind(muhat,v)
v=2.28538535
cbind(muhat,v)
v=2.28538535e-16
cbind(muhat,v)
cbind(muhat,var=v)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat, v, asshat=v)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2);asshat=v#
  cbind(muhat, v, asshat)#
}
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2);asshat=v#
browser;  cbind(muhat, v, asshat)#
}
f2(2)
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2);asshat=v#
browser();  cbind(muhat, v, asshat)#
}
f2(2)
cbind(asshat)
cbind(a=asshat)
cbind(a=asshat,b=1)
cbind(a=asshat,b=2.528696e-14)
cbind(a=asshat,b=2.528696e-14*1)
cbind(a=asshat,b=asshat)
cbind(a=asshat,b=asshat*1)
cbind(a=asshat,b=as.numeric(asshat))
class(asshat)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, var=as.numeric(v))#
}
f2(2)
k <- (0:9)/2#
cbind(k, sapply(k, f2)
)
sapply(k,f2)
apply(k,1,f2)
lapply(k,f2)
unlist(.Last.value)
sapply(k,f2)
?sapply
vapply(k, f2)
sapply(k,f2, simp=F)
sapply(k,f2, simplify=F)
t(sapply(k,f2))
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  rbind(muhat=muhat, var=as.numeric(v))#
}
f2(2)
t(sapply(k,f2))
sapply(k,f2)
sapply(k,f2)
k <- (0:9)/2#
cbind(k, t(sapply(k, f2)), colnames=c("k", "muhat", "var"))
?cbind
data.frame(paste("k=",k), t(sapply(k,f2)))
data.frame(paste("k=",k), t(sapply(k,f2)),colnames=NULL)
?data.frame
data.frame(paste("k=",k), t(sapply(k,f2)),col.names=NULL)
data.frame(paste("k=",k), t(sapply(k,f2)), dimnames=NULL)
sapply((0:9)/2, f2)
k <- (0:9)/2#
rbind(k, sapply(k, f2))
k <- (0:9)/2#
rbind(sapply(k, f2))
k <- (0:9)/2#
rbind(k, sapply(k, f2))
sapply(k, f2)[2,]
set.seed(12345) # Set seed so we can exactly replicate sample#
f2(2)[,2] # This is the ratio imp. samp. estimated variance#
set.seed(12345) #
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2))
f2(2)
f2 <- function(k, n=1e5) {#
  x <- rnorm(n) + k#
  b <- exp((x-k)^2/2 - x^2/2)#
  a <- (x>4.5)*b#
  muhat <- mean(a) / mean(b)#
  v <- (z <- c(1, -muhat)) %*% cov(cbind(a,b)) %*% z / (n*mean(b)^2)#
  cbind(muhat=muhat, var=as.numeric(v))#
}
set.seed(12345) # Set seed so we can exactly replicate sample#
f2(2)[,2] # This is the ratio imp. samp. estimated variance#
set.seed(12345) #
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2))
set.seed(12345) # Set seed so we can exactly replicate sample#
f2(2)[,2] # This is the ratio imp. samp. estimated variance#
set.seed(12345) #
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5
theta0 <- 1#
y <- rbinom(1e6, 100, exp(theta0)/(1+exp(theta0)))
xobs <- 80#
ell <- function(theta) (theta-theta0)*xobs - log(mean(exp((theta-theta0)*y)))
th <- seq(0, 2, len=200)#
ellth <- sapply(th, ell)
plot(th, ellth, type="l", lwd=2, lty=2, col=2)#
lines(th, (th-theta0)*xobs - n*log((1+exp(th))/(1+exp(theta0)))
)
plot(th, ellth, type="l", lwd=2, lty=2, col=2)#
lines(th, (th-theta0)*xobs - 100*log((1+exp(th))/(1+exp(theta0))))
th <- seq(-1, 3, len=200)#
system.time(ellth <- sapply(th, ell))
plot(th, ellth, type="l", lwd=2, lty=2, col=2)#
lines(th, (th-theta0)*xobs - 100*log((1+exp(th))/(1+exp(theta0))))
plot(th, ellth, type="l", lwd=2, lty=2, col=2, xlab=expression(theta),#
    ylab=expression(l(theta)))#
lines(th, (th-theta0)*xobs - 100*log((1+exp(th))/(1+exp(theta0))))
plot(th, ellth, type="l", lwd=2, lty=2, col=2, xlab=expression(theta),#
    ylab=expression(ell(theta)))#
lines(th, (th-theta0)*xobs - 100*log((1+exp(th))/(1+exp(theta0))))
th <- seq(-1, 3, len=501)#
system.time(ellth <- sapply(th, ell))
plot(th, ellth, type="l", lwd=3, lty=2, col=2, xlab=expression(theta),#
    ylab=expression(l(theta)))#
lines(th, (th-theta0)*xobs - 100*log((1+exp(th))/(1+exp(theta0))), lwd=3)#
abline(v=log(4), lwd=2)#
abline(v=th[which.max(ellth)], lwd=2, lty=2, col=2)
theta0 <- 0#
y <- rbinom(1e6, 100, exp(theta0)/(1+exp(theta0)))#
th <- seq(-1, 3, len=501)#
system.time(ellth <- sapply(th, ell))#
plot(th, ellth, type="l", lwd=3, lty=2, col=2, xlab=expression(theta),#
    ylab=expression(l(theta)))#
lines(th, (th-theta0)*xobs - 100*log((1+exp(th))/(1+exp(theta0))), lwd=3)#
abline(v=log(4), lwd=2)
f(2)
f <- function(k, n=10) {#
  muhat <- 1:n#
  for (i in 1:n) {#
    x <- rnorm(1e5) + k#
    b <- exp((x-k)^2/2 - x^2/2)#
    a <- (x>4.5)*b#
    muhat[i] <- mean(a) / mean(b)#
  }#
  muhat#
}
f(2)
var(f(2))
var(f(2))
var(f(2))
var(f(2))
var(f(2))
var(f(2,n=100))
var(f(2,n=100))
var(f(2,n=100))
var(f(2,n=1000))
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
x <- rnorm(1e5)+2#
var((x>4.5) * dnorm(x) / dnorm(x-2)) / 1e5 # Plain imp. samp.
q()
q()
